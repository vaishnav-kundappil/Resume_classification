{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071a4223-265b-453d-855e-13d047f9e8b8",
   "metadata": {},
   "source": [
    "# RESUME CLASSIFICATION EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305ce76d-016f-45e3-a929-69dc5f5a4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the OS module to interact with the operating system\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b0d077-2b72-4919-b5f2-25d7c880da1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\revat\\\\Desktop\\\\Excelr\\\\Project2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c29db8e-d6ba-4d5e-a50b-00c889e704fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\revat\\anaconda3\\lib\\site-packages (25.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ordcloud (c:\\users\\revat\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "WARNING: Error parsing dependencies of pyzmq: Invalid version: 'cpython'\n",
      "WARNING: Ignoring invalid distribution -ordcloud (c:\\users\\revat\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"C:\\Users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"C:\\Users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 484, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"C:\\Users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"C:\\Users\\revat\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"C:\\Users\\revat\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: {version!r}\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\revat\\anaconda3\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\revat\\anaconda3\\lib\\site-packages (from wordcloud) (1.22.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\revat\\anaconda3\\lib\\site-packages (from wordcloud) (9.5.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\revat\\anaconda3\\lib\\site-packages (from wordcloud) (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\revat\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\revat\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\revat\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\revat\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\revat\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\revat\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\revat\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ordcloud (c:\\users\\revat\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "WARNING: Error parsing dependencies of pyzmq: Invalid version: 'cpython'\n",
      "WARNING: Ignoring invalid distribution -ordcloud (c:\\users\\revat\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 484, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\revat\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (6.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\revat\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\revat\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->wordcloud) (3.20.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    return parse_version(self._dist.version)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: {version!r}\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0640e2d1-a015-4ee0-9bd6-e4b5af44139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "import pandas as pd   # Data handling and analysis\n",
    "import seaborn as sns   # Statistical data visualization\n",
    "from matplotlib import pyplot as plt   # General plotting\n",
    "import os\n",
    "import warnings   # Handling warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "# Importing NLP-related libraries\n",
    "import re   # Regular expressions for text processing\n",
    "import nltk   # Natural Language Toolkit for NLP tasks\n",
    "import string   # Handling punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00564767-6a29-48c2-90e4-481efd5b96a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Peoplesoft',\n",
       " 'Peoplesoft Resume',\n",
       " 'React Developer',\n",
       " 'SQL Developer',\n",
       " 'workday']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all files and directories inside the specified folder\n",
    "os.listdir(r'C:\\\\Users\\\\revat\\\\Desktop\\\\Excelr\\\\Project2\\\\Dataset\\Resumes_Docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a81b8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\revat\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\revat\\anaconda3\\lib\\site-packages (from python-docx) (4.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\revat\\anaconda3\\lib\\site-packages (from python-docx) (4.12.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ordcloud (c:\\users\\revat\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "WARNING: Error parsing dependencies of pyzmq: Invalid version: 'cpython'\n",
      "WARNING: Ignoring invalid distribution -ordcloud (c:\\users\\revat\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 484, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: {version!r}\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    }
   ],
   "source": [
    "!pip install python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a424431-9474-4948-80fa-17de5020ea34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resumes processed: 20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx\n",
    "import win32com.client\n",
    "\n",
    "file_path1 = []\n",
    "category1  = []\n",
    "directory1 = r'C:\\\\Users\\\\revat\\\\Desktop\\\\Excelr\\\\Project2\\\\Dataset\\\\Resumes_Docx\\Peoplesoft Resume'  \n",
    "\n",
    "def extract_text_docx(docx_path):\n",
    "    \"\"\"Extract text from a .docx file\"\"\"\n",
    "    doc = docx.Document(docx_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def extract_text_doc(doc_path):\n",
    "    \"\"\"Extract text from a .doc file using pywin32 (Windows only)\"\"\"\n",
    "    word = win32com.client.Dispatch(\"Word.Application\")\n",
    "    word.Visible = False\n",
    "    try:\n",
    "        doc = word.Documents.Open(doc_path)\n",
    "        text = doc.Content.Text\n",
    "        doc.Close(False)  # Close without saving\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {doc_path}: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        word.Quit()\n",
    "\n",
    "for filename in os.listdir(directory1):\n",
    "    file_path = os.path.join(directory1, filename)\n",
    "    \n",
    "    if filename.endswith('.docx'):\n",
    "        text = extract_text_docx(file_path)\n",
    "    elif filename.endswith('.doc'):\n",
    "        text = extract_text_doc(file_path)\n",
    "    else:\n",
    "        continue  # Skip non-document files\n",
    "\n",
    "    if text:\n",
    "        file_path1.append(text)\n",
    "        category1.append('Peoplesoft Resume')\n",
    "\n",
    "print(f\"Total resumes processed: {len(file_path1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74dc5e47-f788-4045-b30f-64a568bc312b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw_Details</th>\n",
       "      <th>Category1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\r\\r\\r\\r\\r\\r\\t\\r\\rProfile Summary:\\t\\t\\t\\t\\t\\t...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PeopleSoft Database Administrator\\r           ...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Murali\\n\\nExperience Summary \\n\\nI have 6 year...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Priyanka Ramadoss\\r61/46, MountPleasant, \\rCoo...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPROFILE SUMMARY\\n\\...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PEOPLESOFT ADMINISTRATOR\\r\\r\\rSRINIVAS.K \\t\\t\\...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PeopleSoft Admin\\nVARKALA VIKAS\\n\\nCareer Obj...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vinod Akkala                                  ...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PeopleSoft Admin/PeopleSoft DBA\\r\\rGanesh All...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PeopleSoft Administration\\n \\nVivekanand Sayan...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Arun Venu\\r\\r  EXPERIENCE SUMMARY\\t\\r\\rExperie...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Personal Details\\t\\t\\r\u0007\\r\u0007Name\\r\u0007Pritam Biswas...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rahul Ahuja\\r---------------------------------...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\\nHaving 4.6 years of experience in PeopleSoft...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\nHaving 4.6 years of experience in PeopleSoft...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\\n\\nCAREER OBJECTIVE\\t\\t\\n\\nPursuing Peopleso...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\\rR Ahmed                                     ...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tanna Sujatha \\n\\n\\n\\nOBJECTIVE\\nSeeking a cha...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nC O N ...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Raw_Details          Category1\n",
       "0     Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...  Peoplesoft Resume\n",
       "1   \\r\\r\\r\\r\\r\\r\\t\\r\\rProfile Summary:\\t\\t\\t\\t\\t\\t...  Peoplesoft Resume\n",
       "2   PeopleSoft Database Administrator\\r           ...  Peoplesoft Resume\n",
       "3   Murali\\n\\nExperience Summary \\n\\nI have 6 year...  Peoplesoft Resume\n",
       "4   Priyanka Ramadoss\\r61/46, MountPleasant, \\rCoo...  Peoplesoft Resume\n",
       "5   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPROFILE SUMMARY\\n\\...  Peoplesoft Resume\n",
       "6   PEOPLESOFT ADMINISTRATOR\\r\\r\\rSRINIVAS.K \\t\\t\\...  Peoplesoft Resume\n",
       "7    PeopleSoft Admin\\nVARKALA VIKAS\\n\\nCareer Obj...  Peoplesoft Resume\n",
       "8   Vinod Akkala                                  ...  Peoplesoft Resume\n",
       "9    PeopleSoft Admin/PeopleSoft DBA\\r\\rGanesh All...  Peoplesoft Resume\n",
       "10  PeopleSoft Administration\\n \\nVivekanand Sayan...  Peoplesoft Resume\n",
       "11  Arun Venu\\r\\r  EXPERIENCE SUMMARY\\t\\r\\rExperie...  Peoplesoft Resume\n",
       "12  Personal Details\\t\\t\\r\u0007\\r\u0007Name\\r\u0007Pritam Biswas...  Peoplesoft Resume\n",
       "13  Rahul Ahuja\\r---------------------------------...  Peoplesoft Resume\n",
       "14  \\nHaving 4.6 years of experience in PeopleSoft...  Peoplesoft Resume\n",
       "15  \\nHaving 4.6 years of experience in PeopleSoft...  Peoplesoft Resume\n",
       "16   \\n\\nCAREER OBJECTIVE\\t\\t\\n\\nPursuing Peopleso...  Peoplesoft Resume\n",
       "17  \\rR Ahmed                                     ...  Peoplesoft Resume\n",
       "18  Tanna Sujatha \\n\\n\\n\\nOBJECTIVE\\nSeeking a cha...  Peoplesoft Resume\n",
       "19  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nC O N ...  Peoplesoft Resume"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.DataFrame(data = file_path1 , columns = ['Raw_Details'])\n",
    "data1['Category1'] = category1\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adae2c5a-c823-4c47-900b-e5b2c528313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\revat\\anaconda3\\lib\\site-packages (1.24.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ordcloud (c:\\users\\revat\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "WARNING: Error parsing dependencies of pyzmq: Invalid version: 'cpython'\n",
      "WARNING: Ignoring invalid distribution -ordcloud (c:\\users\\revat\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 484, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: {version!r}\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    }
   ],
   "source": [
    "# Installing PyMuPDF (pymupdf) for working with PDFs in Python\n",
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a6b28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\revat\\anaconda3\\lib\\site-packages (1.24.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ordcloud (c:\\users\\revat\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "WARNING: Error parsing dependencies of pyzmq: Invalid version: 'cpython'\n",
      "WARNING: Ignoring invalid distribution -ordcloud (c:\\users\\revat\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 484, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"c:\\users\\revat\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: {version!r}\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c7b4a32-3bb6-465e-8e59-f686598b20c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resumes processed: 24\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx\n",
    "import fitz  # PyMuPDF for PDFs\n",
    "import win32com.client\n",
    "\n",
    "file_path2 = []\n",
    "category2 = []\n",
    "directory2 = r'C:\\\\Users\\\\revat\\\\Desktop\\\\Excelr\\\\Project2\\\\Dataset\\\\Resumes_Docx\\React Developer'\n",
    "\n",
    "def extract_text_docx(docx_path):\n",
    "    \"\"\"Extract text from a .docx file\"\"\"\n",
    "    try:\n",
    "        doc = docx.Document(docx_path)\n",
    "        return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {docx_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_text_doc(doc_path):\n",
    "    \"\"\"Extract text from a .doc file using win32com (Windows only)\"\"\"\n",
    "    if not os.path.exists(doc_path):\n",
    "        print(f\"File not found: {doc_path}\")\n",
    "        return None\n",
    "\n",
    "    word = win32com.client.Dispatch(\"Word.Application\")\n",
    "    word.Visible = False  # Run Word in the background\n",
    "\n",
    "    try:\n",
    "        doc = word.Documents.Open(doc_path)\n",
    "        text = doc.Content.Text\n",
    "        doc.Close(False)  # Close without saving\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {doc_path}: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        word.Quit()  # Ensure Word quits properly\n",
    "\n",
    "def extract_text_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file using PyMuPDF\"\"\"\n",
    "    try:\n",
    "        text = \"\"\n",
    "        with fitz.open(pdf_path) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text(\"text\") + \"\\n\"\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {pdf_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process files\n",
    "for filename in os.listdir(directory2):\n",
    "    file_path = os.path.join(directory2, filename)\n",
    "    text = None\n",
    "\n",
    "    if filename.endswith('.docx'):\n",
    "        text = extract_text_docx(file_path)\n",
    "    elif filename.endswith('.doc'):\n",
    "        text = extract_text_doc(file_path)\n",
    "    elif filename.endswith('.pdf'):\n",
    "        text = extract_text_pdf(file_path)\n",
    "    else:\n",
    "        continue  # Skip unsupported files\n",
    "\n",
    "    if text:\n",
    "        file_path2.append(text)\n",
    "        category2.append('React Developer')\n",
    "\n",
    "print(f\"Total resumes processed: {len(file_path2)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fc2767a-fb10-4ce5-90dd-a522fe97dab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw_Details</th>\n",
       "      <th>Category2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name: Ravali P \\n\\n                           ...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nSUSOVAN  BAG   \\nSeeking  a  challenging  ...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanumuru Deepak Reddy\\n\\n\\n\\nCAREER OBJECTIVE:...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HARIPRIYA BATTINA \\nExperience as UI Developer...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KAMALAKAR REDDY. A \\nLinked In: https://www.li...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nNaveen Sadhu\\n\\n\\nTitle: software developer\\...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\u0001\u0015\\r\\r\f",
       "PROFILE\\rSearching for the opportunity ...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\nPRAGNYA PATTNAIK\\n \\n \\n \\n Expertise: \\n \\...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\n 204,Sri geethika prestige,road number 10...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n\\nThirupathamma Balla\\n\\nSUMMARY:\\n\\n2.8 yea...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Maryala Vinay Reddy\\r\\rProfessional Summary:\\t...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\nUi-Developer/ React JS Developer \\nNAME: KRI...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\nUi-Developer/ React JS Developer \\nNAME: KRI...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CURRICULUM VITAE\\r\\r\\r\\rAnjani Priyadarshini\\r...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kotani Durga Prasad\\n\\n\\nObjective:\\n\\nAspiran...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Venkatalakshmi Pedireddy\\nSoftware Developer\\n...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KAMBALA SAI SURENDRA   \\n \\n\\tMandepeta \\t \\n ...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MAREEDU LOKESH BABU\\nPROFESSIONAL OVERVIEW\\n  ...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MAREEDU LOKESH BABU\\n\\nPROFESSIONAL OVERVIEW\\n...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MD KHIZARUDDIN RAUF \\n \\t EXPERIENCE \\n     \\n...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Page | 1  \\n \\nName: M. Prabakaran \\nTitle: UI...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\\nPranish Sonone\\n\\t\\n\\n\\n\\n\\nCareer summary:\\...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ranga Gaganam  \\n \\n \\nHaving 1+ years of succ...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SHAIK ABDUL SHARUK   \\n2 years’ Experience in ...</td>\n",
       "      <td>React Developer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Raw_Details        Category2\n",
       "0   Name: Ravali P \\n\\n                           ...  React Developer\n",
       "1     \\nSUSOVAN  BAG   \\nSeeking  a  challenging  ...  React Developer\n",
       "2   Kanumuru Deepak Reddy\\n\\n\\n\\nCAREER OBJECTIVE:...  React Developer\n",
       "3   HARIPRIYA BATTINA \\nExperience as UI Developer...  React Developer\n",
       "4   KAMALAKAR REDDY. A \\nLinked In: https://www.li...  React Developer\n",
       "5   \\nNaveen Sadhu\\n\\n\\nTitle: software developer\\...  React Developer\n",
       "6   \u0001\u0015\\r\\r\n",
       "PROFILE\\rSearching for the opportunity ...  React Developer\n",
       "7    \\nPRAGNYA PATTNAIK\\n \\n \\n \\n Expertise: \\n \\...  React Developer\n",
       "8   \\n\\n 204,Sri geethika prestige,road number 10...  React Developer\n",
       "9   \\n\\nThirupathamma Balla\\n\\nSUMMARY:\\n\\n2.8 yea...  React Developer\n",
       "10  Maryala Vinay Reddy\\r\\rProfessional Summary:\\t...  React Developer\n",
       "11  \\nUi-Developer/ React JS Developer \\nNAME: KRI...  React Developer\n",
       "12  \\nUi-Developer/ React JS Developer \\nNAME: KRI...  React Developer\n",
       "13  CURRICULUM VITAE\\r\\r\\r\\rAnjani Priyadarshini\\r...  React Developer\n",
       "14  Kotani Durga Prasad\\n\\n\\nObjective:\\n\\nAspiran...  React Developer\n",
       "15  Venkatalakshmi Pedireddy\\nSoftware Developer\\n...  React Developer\n",
       "16  KAMBALA SAI SURENDRA   \\n \\n\\tMandepeta \\t \\n ...  React Developer\n",
       "17  MAREEDU LOKESH BABU\\nPROFESSIONAL OVERVIEW\\n  ...  React Developer\n",
       "18  MAREEDU LOKESH BABU\\n\\nPROFESSIONAL OVERVIEW\\n...  React Developer\n",
       "19  MD KHIZARUDDIN RAUF \\n \\t EXPERIENCE \\n     \\n...  React Developer\n",
       "20  Page | 1  \\n \\nName: M. Prabakaran \\nTitle: UI...  React Developer\n",
       "21  \\nPranish Sonone\\n\\t\\n\\n\\n\\n\\nCareer summary:\\...  React Developer\n",
       "22  Ranga Gaganam  \\n \\n \\nHaving 1+ years of succ...  React Developer\n",
       "23  SHAIK ABDUL SHARUK   \\n2 years’ Experience in ...  React Developer"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.DataFrame(data = file_path2 , columns = ['Raw_Details'])\n",
    "data2['Category2'] = category2\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d7f12d-bf6f-46a0-a49f-23ae4640ae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resumes processed: 14\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx\n",
    "import win32com.client  # For .doc files (Windows only)\n",
    "\n",
    "file_path3 = []\n",
    "category3  = []\n",
    "directory3 = r'C:\\\\Users\\\\revat\\\\Desktop\\\\Excelr\\\\Project2\\\\Dataset\\\\Resumes_Docx\\SQL Developer/' \n",
    "def extract_text_docx(docx_path):\n",
    "    \"\"\"Extract text from a .docx file\"\"\"\n",
    "    try:\n",
    "        doc = docx.Document(docx_path)\n",
    "        return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {docx_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_text_doc(doc_path):\n",
    "    \"\"\"Extract text from a .doc file using pywin32 (Windows only)\"\"\"\n",
    "    word = win32com.client.Dispatch(\"Word.Application\")\n",
    "    word.Visible = False  # Run in the background\n",
    "\n",
    "    try:\n",
    "        doc = word.Documents.Open(doc_path)\n",
    "        text = doc.Content.Text\n",
    "        doc.Close(False)  # Close without saving\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {doc_path}: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        word.Quit()  # Ensure Word quits properly\n",
    "\n",
    "# Process both .doc and .docx files\n",
    "for filename in os.listdir(directory3):\n",
    "    if filename.endswith(('.docx', '.doc')):  # Check both extensions\n",
    "        file_path = os.path.join(directory3, filename)\n",
    "        text = None\n",
    "\n",
    "        if filename.endswith('.docx'):\n",
    "            text = extract_text_docx(file_path)\n",
    "        elif filename.endswith('.doc'):\n",
    "            text = extract_text_doc(file_path)\n",
    "\n",
    "        if text:\n",
    "            file_path3.append(text)\n",
    "            category3.append('SQL Developer')\n",
    "\n",
    "print(f\"Total resumes processed: {len(file_path3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90199ac1-9e2a-4aa2-8b9e-a90cec43bf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw_Details</th>\n",
       "      <th>Category3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANIL KUMAR MADDUKURI  \\t\\t\\nSQL &amp; MSBI Develop...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nAradhana Tripathi\\n\\nCurrent Location: Gachi...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUDDHA VAMSI                                  ...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KAMBALLA PRADEEP                              ...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\r\\r Hyderabad\\r\u000eNazeer Basha\\rSQL and Power...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n                                        Res...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SQL DEVELOPER\\nName: -   Bandi prem sai\\n\\n\\nW...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SQL SER...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SQL SER...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RAJU PAVANA KUMARI\\n\\n\\nProfessional Summary:...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>resume\\n\\n...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Name: Ramesh\\n\\nCareer Objective: \\n          ...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Career objective\\r\\t\\rA rewarding opportunity ...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B. vinod kumar\\n\\nOBJECTIVE:\\nWilling to work ...</td>\n",
       "      <td>SQL Developer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Raw_Details      Category3\n",
       "0   ANIL KUMAR MADDUKURI  \\t\\t\\nSQL & MSBI Develop...  SQL Developer\n",
       "1   \\nAradhana Tripathi\\n\\nCurrent Location: Gachi...  SQL Developer\n",
       "2   BUDDHA VAMSI                                  ...  SQL Developer\n",
       "3   KAMBALLA PRADEEP                              ...  SQL Developer\n",
       "4   \n",
       "\\r\\r Hyderabad\\r\u000eNazeer Basha\\rSQL and Power...  SQL Developer\n",
       "5    \\n                                        Res...  SQL Developer\n",
       "6   SQL DEVELOPER\\nName: -   Bandi prem sai\\n\\n\\nW...  SQL Developer\n",
       "7                                          SQL SER...  SQL Developer\n",
       "8                                          SQL SER...  SQL Developer\n",
       "9    RAJU PAVANA KUMARI\\n\\n\\nProfessional Summary:...  SQL Developer\n",
       "10                                      resume\\n\\n...  SQL Developer\n",
       "11  Name: Ramesh\\n\\nCareer Objective: \\n          ...  SQL Developer\n",
       "12  Career objective\\r\\t\\rA rewarding opportunity ...  SQL Developer\n",
       "13  B. vinod kumar\\n\\nOBJECTIVE:\\nWilling to work ...  SQL Developer"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3 = pd.DataFrame(data = file_path3 , columns = ['Raw_Details'])\n",
    "data3['Category3'] = category3\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db40350-2e6d-4030-8bdd-5677327827d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resumes extracted: 21\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx\n",
    "import win32com.client  # For .doc files (Windows only)\n",
    "\n",
    "file_path4 = []\n",
    "category4  = []\n",
    "directory4 = 'C:\\\\Users\\\\revat\\\\Desktop\\\\Excelr\\\\Project2\\\\Dataset\\\\Resumes_Docx\\workday'  \n",
    "def extract_text_docx(docx_path):\n",
    "    \"\"\"Extract text from a .docx file\"\"\"\n",
    "    try:\n",
    "        doc = docx.Document(docx_path)\n",
    "        return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {docx_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_text_doc(doc_path):\n",
    "    \"\"\"Extract text from a .doc file using pywin32 (Windows only)\"\"\"\n",
    "    word = win32com.client.Dispatch(\"Word.Application\")\n",
    "    word.Visible = False  # Run in the background\n",
    "\n",
    "    try:\n",
    "        doc = word.Documents.Open(doc_path)\n",
    "        text = doc.Content.Text\n",
    "        doc.Close(False)  # Close without saving\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {doc_path}: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        word.Quit()  # Ensure Word quits properly\n",
    "\n",
    "# Process both .doc and .docx files\n",
    "for filename in os.listdir(directory4):\n",
    "    if filename.endswith(('.docx', '.doc')):  # Check both extensions\n",
    "        file_path = os.path.join(directory4, filename)\n",
    "        text = None\n",
    "\n",
    "        if filename.endswith('.docx'):\n",
    "            text = extract_text_docx(file_path)\n",
    "        elif filename.endswith('.doc'):\n",
    "            text = extract_text_doc(file_path)\n",
    "\n",
    "        if text and text.strip():  # Ensure text is not empty\n",
    "            file_path4.append(text)\n",
    "            category4.append('workday')\n",
    "\n",
    "print(f\"Total resumes extracted: {len(file_path4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0a7b121-2092-4eb8-8204-210f0f9b3e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw_Details</th>\n",
       "      <th>Category4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinna Subbarayudu M\\nDOB: 06th March 1994\\nNa...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\t\\n\\n\\nName         : Gopi Krishna Reddy\\n\\t\\...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hari Krishna M\\r\\r\\rSummary:\\rA result oriente...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harikrishna Akula                             ...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HIMA.MENDU\\r  \\r\\rCareer Objective\\rTo continu...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n      ...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\u0001\\t\\t\\t\\t\\t\\t\\tName:\\tJ. Sumanth Royal.\\r\\t\\rP...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n\\nJYOTI VERMA\\t\\t\\t\\t\\t\\n\\n\\n\\n3 years of Ex...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\t\\t\\t\\t\\tMadeeswar A\\r\\t\\r\\t\\rPROFILE SUMMARY...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n\\nMooraboyina Guravaiah\\nWorkday Integration...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Name\\t: Naresh Babu Cherukuri\\r\\rObjective:\\rT...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VENKATA SAIKRISHNA\\n Workday Consultant\\n\\n\\nP...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\u0001\u0015\\r\u0001\u0015\\r\\r3.3 years of IT experience as Workda...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rahul  (Techno Functional Consultant)  \\nProfe...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ramesh A\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Shireesh Balasani                             ...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\\tWorkday Integration Consultant\\r\\rName      ...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Seeking suitable positions in Workday HCM  as ...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\\nWORKDAY | HCM | FCM\\nName \\t\\t: Kumar S.S\\nR...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Venkateswarlu.B\\t\\t\\t\\t\\t\\t\\t\\tWorkday Consult...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>...</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Raw_Details Category4\n",
       "0   Chinna Subbarayudu M\\nDOB: 06th March 1994\\nNa...   workday\n",
       "1   \\t\\n\\n\\nName         : Gopi Krishna Reddy\\n\\t\\...   workday\n",
       "2   Hari Krishna M\\r\\r\\rSummary:\\rA result oriente...   workday\n",
       "3   Harikrishna Akula                             ...   workday\n",
       "4   HIMA.MENDU\\r  \\r\\rCareer Objective\\rTo continu...   workday\n",
       "5                                         \\n      ...   workday\n",
       "6   \u0001\\t\\t\\t\\t\\t\\t\\tName:\\tJ. Sumanth Royal.\\r\\t\\rP...   workday\n",
       "7   \\n\\nJYOTI VERMA\\t\\t\\t\\t\\t\\n\\n\\n\\n3 years of Ex...   workday\n",
       "8   \\t\\t\\t\\t\\tMadeeswar A\\r\\t\\r\\t\\rPROFILE SUMMARY...   workday\n",
       "9   \\n\\nMooraboyina Guravaiah\\nWorkday Integration...   workday\n",
       "10  Name\\t: Naresh Babu Cherukuri\\r\\rObjective:\\rT...   workday\n",
       "11  VENKATA SAIKRISHNA\\n Workday Consultant\\n\\n\\nP...   workday\n",
       "12  \u0001\u0015\\r\u0001\u0015\\r\\r3.3 years of IT experience as Workda...   workday\n",
       "13  Rahul  (Techno Functional Consultant)  \\nProfe...   workday\n",
       "14  Ramesh A\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t...   workday\n",
       "15  Shireesh Balasani                             ...   workday\n",
       "16  \\tWorkday Integration Consultant\\r\\rName      ...   workday\n",
       "17  Seeking suitable positions in Workday HCM  as ...   workday\n",
       "18  \\nWORKDAY | HCM | FCM\\nName \\t\\t: Kumar S.S\\nR...   workday\n",
       "19  Venkateswarlu.B\\t\\t\\t\\t\\t\\t\\t\\tWorkday Consult...   workday\n",
       "20                                                ...   workday"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4 = pd.DataFrame(data=file_path4, columns=['Raw_Details'])\n",
    "data4['Category4'] = category4\n",
    "data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "997d61b5-87de-43d6-8554-757c44a93989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Raw_Details          Category1  \\\n",
      "0     Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...  Peoplesoft Resume   \n",
      "1   \\r\\r\\r\\r\\r\\r\\t\\r\\rProfile Summary:\\t\\t\\t\\t\\t\\t...  Peoplesoft Resume   \n",
      "2   PeopleSoft Database Administrator\\r           ...  Peoplesoft Resume   \n",
      "3   Murali\\n\\nExperience Summary \\n\\nI have 6 year...  Peoplesoft Resume   \n",
      "4   Priyanka Ramadoss\\r61/46, MountPleasant, \\rCoo...  Peoplesoft Resume   \n",
      "..                                                ...                ...   \n",
      "74  \\tWorkday Integration Consultant\\r\\rName      ...                NaN   \n",
      "75  Seeking suitable positions in Workday HCM  as ...                NaN   \n",
      "76  \\nWORKDAY | HCM | FCM\\nName \\t\\t: Kumar S.S\\nR...                NaN   \n",
      "77  Venkateswarlu.B\\t\\t\\t\\t\\t\\t\\t\\tWorkday Consult...                NaN   \n",
      "78                                                ...                NaN   \n",
      "\n",
      "   Category2 Category3 Category4  \n",
      "0        NaN       NaN       NaN  \n",
      "1        NaN       NaN       NaN  \n",
      "2        NaN       NaN       NaN  \n",
      "3        NaN       NaN       NaN  \n",
      "4        NaN       NaN       NaN  \n",
      "..       ...       ...       ...  \n",
      "74       NaN       NaN   workday  \n",
      "75       NaN       NaN   workday  \n",
      "76       NaN       NaN   workday  \n",
      "77       NaN       NaN   workday  \n",
      "78       NaN       NaN   workday  \n",
      "\n",
      "[79 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Assuming data1, data2, data3, and data4 are DataFrames\n",
    "resume_data = pd.concat([data1, data2, data3, data4], ignore_index=True)\n",
    "print(resume_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12ce90c4-97f5-4d08-b7f4-f5274fba1447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79 entries, 0 to 78\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Raw_Details  79 non-null     object\n",
      " 1   Category1    20 non-null     object\n",
      " 2   Category2    24 non-null     object\n",
      " 3   Category3    14 non-null     object\n",
      " 4   Category4    21 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "resume_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9aa6414e-c28c-4276-b17d-d306cfa8a69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw_Details</th>\n",
       "      <th>Category1</th>\n",
       "      <th>Category2</th>\n",
       "      <th>Category3</th>\n",
       "      <th>Category4</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\r\\r\\r\\r\\r\\r\\t\\r\\rProfile Summary:\\t\\t\\t\\t\\t\\t...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PeopleSoft Database Administrator\\r           ...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Murali\\n\\nExperience Summary \\n\\nI have 6 year...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Priyanka Ramadoss\\r61/46, MountPleasant, \\rCoo...</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>\\tWorkday Integration Consultant\\r\\rName      ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>workday</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Seeking suitable positions in Workday HCM  as ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>workday</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>\\nWORKDAY | HCM | FCM\\nName \\t\\t: Kumar S.S\\nR...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>workday</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Venkateswarlu.B\\t\\t\\t\\t\\t\\t\\t\\tWorkday Consult...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>workday</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>workday</td>\n",
       "      <td>workday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Raw_Details          Category1  \\\n",
       "0     Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...  Peoplesoft Resume   \n",
       "1   \\r\\r\\r\\r\\r\\r\\t\\r\\rProfile Summary:\\t\\t\\t\\t\\t\\t...  Peoplesoft Resume   \n",
       "2   PeopleSoft Database Administrator\\r           ...  Peoplesoft Resume   \n",
       "3   Murali\\n\\nExperience Summary \\n\\nI have 6 year...  Peoplesoft Resume   \n",
       "4   Priyanka Ramadoss\\r61/46, MountPleasant, \\rCoo...  Peoplesoft Resume   \n",
       "..                                                ...                ...   \n",
       "74  \\tWorkday Integration Consultant\\r\\rName      ...                NaN   \n",
       "75  Seeking suitable positions in Workday HCM  as ...                NaN   \n",
       "76  \\nWORKDAY | HCM | FCM\\nName \\t\\t: Kumar S.S\\nR...                NaN   \n",
       "77  Venkateswarlu.B\\t\\t\\t\\t\\t\\t\\t\\tWorkday Consult...                NaN   \n",
       "78                                                ...                NaN   \n",
       "\n",
       "   Category2 Category3 Category4           Category  \n",
       "0        NaN       NaN       NaN  Peoplesoft Resume  \n",
       "1        NaN       NaN       NaN  Peoplesoft Resume  \n",
       "2        NaN       NaN       NaN  Peoplesoft Resume  \n",
       "3        NaN       NaN       NaN  Peoplesoft Resume  \n",
       "4        NaN       NaN       NaN  Peoplesoft Resume  \n",
       "..       ...       ...       ...                ...  \n",
       "74       NaN       NaN   workday            workday  \n",
       "75       NaN       NaN   workday            workday  \n",
       "76       NaN       NaN   workday            workday  \n",
       "77       NaN       NaN   workday            workday  \n",
       "78       NaN       NaN   workday            workday  \n",
       "\n",
       "[79 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a new column 'Category' to the DataFrame\n",
    "# This column stores the category labels for each resume\n",
    "resume_data['Category'] = category1 + category2 + category3 + category4\n",
    "resume_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c27df9e5-bd88-43e7-bab3-d047a4345626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the unnecessary category columns as we have merged them into a single 'Category' column\n",
    "resume_data.drop(['Category1', 'Category2', 'Category3', 'Category4'], axis=1, inplace=True)\n",
    "# Reordering the DataFrame to have 'Category' as the first column, followed by 'Raw_Details'\n",
    "resume_data = resume_data[[\"Category\", \"Raw_Details\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f583bc04-45d4-43c4-8c66-0e28fd599f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Raw_Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>\\r\\r\\r\\r\\r\\r\\t\\r\\rProfile Summary:\\t\\t\\t\\t\\t\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>PeopleSoft Database Administrator\\r           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>Murali\\n\\nExperience Summary \\n\\nI have 6 year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peoplesoft Resume</td>\n",
       "      <td>Priyanka Ramadoss\\r61/46, MountPleasant, \\rCoo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Category                                        Raw_Details\n",
       "0  Peoplesoft Resume    Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...\n",
       "1  Peoplesoft Resume  \\r\\r\\r\\r\\r\\r\\t\\r\\rProfile Summary:\\t\\t\\t\\t\\t\\t...\n",
       "2  Peoplesoft Resume  PeopleSoft Database Administrator\\r           ...\n",
       "3  Peoplesoft Resume  Murali\\n\\nExperience Summary \\n\\nI have 6 year...\n",
       "4  Peoplesoft Resume  Priyanka Ramadoss\\r61/46, MountPleasant, \\rCoo..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c795eaa8-8b5f-4066-bf23-cdc42b381bb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to map categories to numbers\n",
    "category_mapping = {\n",
    "    'Peoplesoft Resume': 0,\n",
    "    'React Developer': 1,\n",
    "    'SQL Developer': 2,\n",
    "    'workday': 3\n",
    "}\n",
    "# Assuming the column with categories is named 'category', replace categories with numbers\n",
    "resume_data['Category'] = resume_data['Category'].replace(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cdfc117-e6c5-45d6-a96b-401cce2d8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the cleaned resume data to a CSV file named 'Raw_Resume.csv' \n",
    "# Setting index=False to avoid writing row indices in the CSV file\n",
    "resume_data.to_csv('Raw_Resume.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "800ab692-fd7f-4f6f-aaed-99a422e0764f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Raw_Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\r\\r\\r\\r\\r\\t\\r\\rProfile Summary:\\t\\t\\t\\t\\t\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>PeopleSoft Database Administrator\\r           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Murali\\n\\nExperience Summary \\n\\nI have 6 year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Priyanka Ramadoss\\r61/46, MountPleasant, \\rCoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>\\tWorkday Integration Consultant\\r\\rName      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>3</td>\n",
       "      <td>Seeking suitable positions in Workday HCM  as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>\\nWORKDAY | HCM | FCM\\nName \\t\\t: Kumar S.S\\nR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>Venkateswarlu.B\\t\\t\\t\\t\\t\\t\\t\\tWorkday Consult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Category                                        Raw_Details\n",
       "0          0    Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...\n",
       "1          0  \\r\\r\\r\\r\\r\\r\\t\\r\\rProfile Summary:\\t\\t\\t\\t\\t\\t...\n",
       "2          0  PeopleSoft Database Administrator\\r           ...\n",
       "3          0  Murali\\n\\nExperience Summary \\n\\nI have 6 year...\n",
       "4          0  Priyanka Ramadoss\\r61/46, MountPleasant, \\rCoo...\n",
       "..       ...                                                ...\n",
       "74         3  \\tWorkday Integration Consultant\\r\\rName      ...\n",
       "75         3  Seeking suitable positions in Workday HCM  as ...\n",
       "76         3  \\nWORKDAY | HCM | FCM\\nName \\t\\t: Kumar S.S\\nR...\n",
       "77         3  Venkateswarlu.B\\t\\t\\t\\t\\t\\t\\t\\tWorkday Consult...\n",
       "78         3                                                ...\n",
       "\n",
       "[79 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the saved CSV file 'Raw_Resume.csv' into a pandas DataFrame\n",
    "resume_data = pd.read_csv(\"Raw_Resume.csv\")\n",
    "resume_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9e3da23-10ae-45cb-b6e3-662013609128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category       0\n",
       "Raw_Details    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values in each column of the DataFrame\n",
    "resume_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f301de93-7894-4c0e-9b84-a412f53b4c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79 entries, 0 to 78\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Category     79 non-null     int64 \n",
      " 1   Raw_Details  79 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Displaying information about the DataFrame, including column data types and non-null values\n",
    "print(resume_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5be1d725-84e5-41ed-a2b3-28562bc1d17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw_Details</th>\n",
       "      <th>Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\r\\r\\r\\r\\r\\r\\t\\r\\rProfile Summary:\\t\\t\\t\\t\\t\\t...</td>\n",
       "      <td>1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PeopleSoft Database Administrator\\r           ...</td>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Murali\\n\\nExperience Summary \\n\\nI have 6 year...</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Priyanka Ramadoss\\r61/46, MountPleasant, \\rCoo...</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Raw_Details  Word_Count\n",
       "0    Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...         978\n",
       "1  \\r\\r\\r\\r\\r\\r\\t\\r\\rProfile Summary:\\t\\t\\t\\t\\t\\t...        1431\n",
       "2  PeopleSoft Database Administrator\\r           ...        1346\n",
       "3  Murali\\n\\nExperience Summary \\n\\nI have 6 year...         494\n",
       "4  Priyanka Ramadoss\\r61/46, MountPleasant, \\rCoo...         670"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new column 'Word_Count' that calculates the number of words in each resume\n",
    "resume_data['Word_Count'] = resume_data['Raw_Details'].apply(lambda x: len(str(x).split(\" \")))\n",
    "resume_data[['Raw_Details','Word_Count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332fa7e0-f3ac-4e86-94fa-ea458a929128",
   "metadata": {},
   "source": [
    "# Steps:\n",
    "\n",
    "    1. Convert the text to lowercase.\n",
    "    \n",
    "    2. Remove HTML tags.\n",
    "    \n",
    "    3. Remove URLs.\n",
    "    \n",
    "    4. Remove numbers.\n",
    "    \n",
    "    5. Tokenize the text into words.\n",
    "    \n",
    "    6. Remove stopwords and short words (length <= 2).\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    sentence (str): The input text (resume content).\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    str: The cleaned and preprocessed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "782add0b-88ac-4df6-a172-6c54a0d649e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence = str(sentence).lower()  # Convert to lowercase\n",
    "    sentence = sentence.replace('{html}', \"\")  # Remove specific HTML placeholders\n",
    "\n",
    "    cleanr = re.compile('<.*?>')  # Regex pattern for HTML tags\n",
    "    cleantext = re.sub(cleanr, '', sentence)  # Remove HTML tags\n",
    "\n",
    "    rem_url = re.sub(r'http\\S+', '', cleantext)  # Remove URLs\n",
    "    rem_num = re.sub(r'[0-9]+', '', rem_url)  # Remove numbers\n",
    "\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')  # Tokenizer to extract words\n",
    "    tokens = tokenizer.tokenize(rem_num)  # Tokenize text into words\n",
    "\n",
    "    # Remove stopwords and short words (<= 2 characters)\n",
    "    filtered_words = [w for w in tokens if len(w) > 2 and w not in stopwords.words('english')]\n",
    "\n",
    "    return \" \".join(filtered_words)  # Join words back into a sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1721b2bd-b25e-4b2d-abb9-1af9077bb8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\revat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# Download the stopwords dataset from NLTK\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd5068-ec45-4067-b655-07f81e62ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_data = pd.read_csv('Raw_Resume.csv')\n",
    "# Apply the preprocess function to the 'Raw_Details' column \n",
    "# and store the cleaned text in a new column 'Resume_Details'\n",
    "resume_data['Resume_Details'] = resume_data['Raw_Details'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056fe3d5-eeab-4478-8b9c-ab0736bb75cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410aa953-7417-495d-8164-fcc4731a43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Raw_Details' column from the DataFrame as it's no longer needed \n",
    "# after preprocessing, keeping only the cleaned 'Resume_Details'\n",
    "resume_data.drop(['Raw_Details'], axis=1, inplace=True)\n",
    "resume_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e0bbc-f214-4766-b108-57106bf8210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned resume data to a CSV file without the index column\n",
    "resume_data.to_csv('Cleaned_Resumes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80aacf-801e-4e9b-988e-ab7ff90124a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned resume data from the CSV file\n",
    "resume_data = pd.read_csv('Cleaned_Resumes.csv')\n",
    "resume_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa60cf1-f390-49fd-9d2c-e80e92434b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'Word_Count' column by calculating word count for each resume\n",
    "resume_data['Word_Count'] = resume_data['Resume_Details'].apply(lambda x: len(str(x).split()))\n",
    "resume_data[['Resume_Details','Word_Count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcfdb7b-b6f6-464f-9788-e6b25baa9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the resume details of the 6th record (index 5) in the dataset\n",
    "print(resume_data.Resume_Details[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3257d-f306-4c33-9c06-d1eeea2b4fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Punkt tokenizer for sentence and word tokenization\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45eb6f-6bd3-40fa-81e1-5a0a1851f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneSetOfStopWords = set(stopwords.words('english')+['``',\"''\"])\n",
    "totalWords =[]\n",
    "Sentences = resume_data['Resume_Details'].values\n",
    "cleanedSentences = \"\"\n",
    "for records in Sentences:\n",
    "    cleanedText = preprocess(records)\n",
    "    cleanedSentences += cleanedText\n",
    "    requiredWords = nltk.word_tokenize(cleanedText)\n",
    "    for word in requiredWords:\n",
    "        if word not in oneSetOfStopWords and word not in string.punctuation:\n",
    "            totalWords.append(word)\n",
    "    \n",
    "# Create a frequency distribution of words in the dataset\n",
    "wordfreqdist = nltk.FreqDist(totalWords)\n",
    "# Extract the 50 most common words in the dataset\n",
    "mostcommon = wordfreqdist.most_common(50)\n",
    "print(mostcommon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c250d88-ad78-455c-ad19-6b8e70fcf51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the NLTK library\n",
    "import nltk  \n",
    "\n",
    "# Downloading necessary NLTK resources\n",
    "nltk.download('wordnet')  # WordNet lexical database for lemmatization\n",
    "nltk.download('omw-1.4')  # Open Multilingual WordNet\n",
    "# Importing the WordNet Lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer  \n",
    "# Initializing the WordNet Lemmatizer\n",
    "wn = WordNetLemmatizer()  \n",
    "# Creating an empty list to store lemmatized words\n",
    "lem_words = []\n",
    "# Loop through each word in the word frequency distribution\n",
    "for word in wordfreqdist:\n",
    "    # Apply lemmatization to reduce words to their base form\n",
    "    word = wn.lemmatize(word)  \n",
    "    # Append the lemmatized word to the list\n",
    "    lem_words.append(word)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511641c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow==9.5.0 --force-reinstall\n",
    "!pip uninstall wordcloud -y\n",
    "!pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc50bfb-96d8-49a9-8e6e-be85b3ea4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure cleanedSentences is a string; join if it's a list\n",
    "if isinstance(cleanedSentences, list):\n",
    "    cleanedSentences = \" \".join(cleanedSentences)\n",
    "\n",
    "# Generate the word cloud with enhancements\n",
    "wc = WordCloud(\n",
    "    background_color=\"white\",\n",
    "    colormap=\"viridis\",\n",
    "    stopwords=set(STOPWORDS),\n",
    "    font_path=\"C:/Windows/Fonts/Arial.ttf\"  # Adjust the path based on your OS\n",
    ").generate(cleanedSentences)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c9a9f-34b1-45dd-9377-50be1b5aa2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Distribution\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(data=resume_data, x='Category', palette='coolwarm', order=resume_data['Category'].value_counts().index)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Resume Category Distribution\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfef51c-a5f0-4178-92e3-905e2cb926cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Distribution - Pie Chart\n",
    "plt.figure(figsize=(8,8))\n",
    "resume_data['Category'].value_counts().plot.pie(autopct=\"%1.1f%%\", colors=sns.color_palette(\"coolwarm\", len(resume_data['Category'].unique())))\n",
    "plt.title(\"Resume Category Distribution\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf96120-30c8-4f7e-b145-7169c7265466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_top_words(category, n):\n",
    "    text = \" \".join(resume_data[resume_data['Category'] == category]['Resume_Details'].dropna())\n",
    "    words = text.split()\n",
    "    common_words = Counter(words).most_common(n)\n",
    "    return common_words\n",
    "\n",
    "# For testing\n",
    "for cat in resume_data['Category'].unique():\n",
    "    print(f\"Most common words in {cat} resumes:\")\n",
    "    print(get_top_words(cat, 10))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842649fa-747a-4e2c-ac4e-c30a2bf837e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud for each category\n",
    "for cat in resume_data['Category'].unique():\n",
    "    text = \" \".join(resume_data[resume_data['Category'] == cat]['Resume_Details'].dropna())\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Word Cloud for {cat} Resumes\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8620b0-2e50-4c07-bd23-351e81b1256e",
   "metadata": {},
   "source": [
    "## Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6354961-40c2-473b-8bea-14da5a215c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff4bf5-ecd7-4859-bdfc-2f2a4388d7c6",
   "metadata": {},
   "source": [
    "## Feature Extraction using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1076305d-651c-4960-b4e7-49bd03cde803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(resume_data['Resume_Details'], resume_data['Category'], \n",
    "                                                    test_size=0.2, random_state=42, stratify=resume_data['Category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2acb42d-9853-4e93-8e97-0263199f33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d4d14e-dec8-47cb-8eb8-e27830f9fb36",
   "metadata": {},
   "source": [
    "## Hyperparamter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a85447-e64c-4f13-88a2-03b10d90f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM\n",
    "svm_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "svm_grid = GridSearchCV(SVC(), svm_params, cv=5, scoring='accuracy')\n",
    "svm_grid.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813eab55-67a4-4cde-896a-26ace24d7008",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "rf_params = {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1633220-d771-4299-8ba9-a0afbf9385ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive Bayes\n",
    "b_params = {'alpha': [0.1, 0.5, 1.0]}\n",
    "b_grid = GridSearchCV(MultinomialNB(), b_params, cv=5, scoring='accuracy')\n",
    "b_grid.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a3652-d5db-4aa5-8ddf-9c241a3358ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNN\n",
    "knn_params = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='accuracy')\n",
    "knn_grid.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02804fb5-be19-43ca-a008-71e4f993a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision Tree\n",
    "dt_params = {'max_depth': [10, 20, None], 'criterion': ['gini', 'entropy']}\n",
    "dt_grid = GridSearchCV(DecisionTreeClassifier(), dt_params, cv=5, scoring='accuracy')\n",
    "dt_grid.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05266077-23e8-499a-8fb7-010f80491a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bagging\n",
    "bagging_params = {'n_estimators': [10, 50, 100]}\n",
    "bagging_grid = GridSearchCV(BaggingClassifier(), bagging_params, cv=5, scoring='accuracy')\n",
    "bagging_grid.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffcaf83-032a-47cf-9214-1a393a943c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AdaBoost\n",
    "adaboost_params = {'n_estimators': [50, 100, 200]}\n",
    "adaboost_grid = GridSearchCV(AdaBoostClassifier(), adaboost_params, cv=5, scoring='accuracy')\n",
    "adaboost_grid.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22edcfd-4f59-4a97-8a73-5ee388baa1aa",
   "metadata": {},
   "source": [
    "## Deep Learning Model(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e8bd4-5974-4036-957d-6db0e0645467",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 5000\n",
    "max_len = 200\n",
    "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
    "tokenizer.fit_on_texts(resume_data['Resume_Details'])\n",
    "X_seq = tokenizer.texts_to_sequences(resume_data['Resume_Details'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=max_len)\n",
    "y_encoded = LabelEncoder().fit_transform(resume_data['Category'])\n",
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_pad, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    Embedding(max_words, 100, input_length=max_len),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(len(set(y_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.fit(X_train_lstm, y_train_lstm, epochs=5, batch_size=32, validation_data=(X_test_lstm, y_test_lstm))\n",
    "\n",
    "lstm_accuracy = lstm_model.evaluate(X_test_lstm, y_test_lstm)[1]\n",
    "print(f\"LSTM Model Accuracy: {lstm_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30e094b-3c2d-4092-a2d3-5f25e431c830",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40399a-c0b4-4691-a254-f06fee0c8e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(**b_grid.best_params_),\n",
    "    \"SVM\": SVC(**svm_grid.best_params_),\n",
    "    \"Random Forest\": RandomForestClassifier(**rf_grid.best_params_),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"KNN\": KNeighborsClassifier(**knn_grid.best_params_),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(**dt_grid.best_params_),\n",
    "    \"Bagging\": BaggingClassifier(**bagging_grid.best_params_),\n",
    "    \"AdaBoost\": AdaBoostClassifier(**adaboost_grid.best_params_)\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_model_name = \"\"\n",
    "best_test_accuracy = 0\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    train_preds = model.predict(X_train_tfidf)\n",
    "    test_preds = model.predict(X_test_tfidf)\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    test_accuracy = accuracy_score(y_test, test_preds)\n",
    "    \n",
    "    print(f\"{name} Performance:\\n\", classification_report(y_test, test_preds))\n",
    "    \n",
    "    # Avoid models that overfit (train accuracy = 1.0, test accuracy = 1.0)\n",
    "    if test_accuracy > best_test_accuracy and not (train_accuracy == 1.0 and test_accuracy == 1.0):\n",
    "        best_test_accuracy = test_accuracy\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "\n",
    "print(f\"Best Model: {best_model_name} with Test Accuracy: {best_test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b4e809-8410-4f37-b153-d75376fc0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "model_names = list(models.keys())\n",
    "\n",
    "print(\"Final Model Accuracies:\")\n",
    "for name, model in models.items():\n",
    "    train_preds = model.predict(X_train_tfidf)\n",
    "    test_preds = model.predict(X_test_tfidf)\n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    test_accuracy = accuracy_score(y_test, test_preds)\n",
    "    \n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    \n",
    "    print(f\"{name}: Train Accuracy = {train_accuracy}, Test Accuracy = {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b053a038-ef02-486d-ad51-019275ea126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Train vs Test Accuracy\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(model_names))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(x - bar_width/2, train_accuracies, bar_width, label='Train Accuracy', color='blue')\n",
    "plt.bar(x + bar_width/2, test_accuracies, bar_width, label='Test Accuracy', color='orange')\n",
    "plt.xticks(x, model_names, rotation=45)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Train vs Test Accuracy for Models')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ad98d-2b71-4f35-a1de-557584b48d36",
   "metadata": {},
   "source": [
    "##  Function to Predict Resume Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff75c12-3dec-4e59-b5d2-10ef4483f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Predict Resume Category using Best Model with User Input\n",
    "def predict_resume_category():\n",
    "    resume_text = input(\"Enter resume details: \")\n",
    "    text_transformed = vectorizer.transform([resume_text])\n",
    "    prediction = best_model.predict(text_transformed)\n",
    "    print(\"Predicted Category:\", prediction[0])\n",
    "\n",
    "# User Input Prediction\n",
    "predict_resume_category()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"resume_classifier.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec5a05e-ca3a-4a09-afe5-50f0f19942e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "!pip install streamlit pandas numpy joblib scikit-learn pymupdf python-docx comtypes pyngrok\n",
    "\n",
    "streamlit_code = \"\"\"\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import fitz  # PyMuPDF for PDF processing\n",
    "import docx\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "model = joblib.load('resume_classifier.pkl')\n",
    "vectorizer = joblib.load('vectorizer.pkl')\n",
    "\n",
    "# Category mapping\n",
    "category_mapping = {\n",
    "    'Peoplesoft Resume': 0,\n",
    "    'React Developer': 1,\n",
    "    'SQL Developer': 2,\n",
    "    'workday': 3\n",
    "}\n",
    "\n",
    "# Reverse mapping for prediction output\n",
    "reverse_category_mapping = {v: k for k, v in category_mapping.items()}\n",
    "\n",
    "# Page Configuration\n",
    "st.set_page_config(page_title=\"Resume Classifier\", layout=\"wide\", page_icon=\"📄\")\n",
    "\n",
    "# Custom CSS for Styling\n",
    "st.markdown(\\\"\"\"\n",
    "    <style>\n",
    "    .main {\n",
    "        background-color: #f8f9fa;\n",
    "        padding: 20px;\n",
    "        border-radius: 10px;\n",
    "        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "    }\n",
    "    .stButton > button {\n",
    "        background-color: #007BFF;\n",
    "        color: white;\n",
    "        border-radius: 8px;\n",
    "        padding: 10px 24px;\n",
    "        border: none;\n",
    "    }\n",
    "    .stButton > button:hover {\n",
    "        background-color: #0056b3;\n",
    "    }\n",
    "    </style>\n",
    "\\\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Title and Description\n",
    "st.title(\"📄 Resume Classification App\")\n",
    "st.markdown(\\\"\"\"\n",
    "### Upload a resume and get classification results instantly!\n",
    "Supports **PDF, DOCX, and DOC** formats.\n",
    "\\\"\"\")\n",
    "\n",
    "# Function to extract text from uploaded file\n",
    "def extract_text(file):\n",
    "    \\\"\"\"Extracts text from PDF, DOCX, or DOC files.\\\"\"\"\n",
    "    if file.type == \"application/pdf\":\n",
    "        pdf_reader = fitz.open(stream=file.read(), filetype=\"pdf\")\n",
    "        text = \"\\\\n\".join([page.get_text(\"text\") for page in pdf_reader])\n",
    "    elif file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":  # DOCX\n",
    "        doc = docx.Document(file)\n",
    "        text = \"\\\\n\".join([para.text for para in doc.paragraphs])\n",
    "    elif file.type == \"application/msword\":  # DOC\n",
    "        text = extract_text_from_doc(file)\n",
    "    else:\n",
    "        text = \"\"  # Unsupported format\n",
    "    return text\n",
    "\n",
    "def extract_text_from_doc(file):\n",
    "    \\\"\"\"Extracts text from a DOC file (Windows-only, requires Microsoft Word).\\\"\"\"\n",
    "    try:\n",
    "        import comtypes.client\n",
    "        word = comtypes.client.CreateObject(\"Word.Application\")\n",
    "        word.Visible = False\n",
    "        doc = word.Documents.Open(file.name)\n",
    "        text = doc.Content.Text\n",
    "        doc.Close(False)\n",
    "        word.Quit()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error processing DOC file: {e}\"\n",
    "\n",
    "# Preprocessing Function\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'<.*?>|http\\\\S+|\\\\d+', '', text)  # Remove HTML, URLs, and numbers\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [w for w in tokens if len(w) > 2 and w not in stop_words]\n",
    "\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# File Upload Section\n",
    "uploaded_file = st.file_uploader(\"Upload your resume\", type=[\"pdf\", \"docx\", \"doc\"])\n",
    "\n",
    "if uploaded_file:\n",
    "    # Extract text\n",
    "    resume_text = extract_text(uploaded_file)\n",
    "    \n",
    "    if resume_text:\n",
    "        # Preprocess text\n",
    "        cleaned_text = preprocess(resume_text)\n",
    "        \n",
    "        # Transform using the vectorizer\n",
    "        transformed_text = vectorizer.transform([cleaned_text])\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(transformed_text)\n",
    "        \n",
    "        # Map prediction to category name\n",
    "        category_name = reverse_category_mapping.get(prediction[0], \"Unknown Category\")\n",
    "        \n",
    "        # Display output\n",
    "        st.markdown(\"### 🏆 Classification Result\")\n",
    "        st.success(f\"The model predicts: **{category_name}**\")\n",
    "    else:\n",
    "        st.error(\"Error: Unable to extract text from the uploaded file.\")\n",
    "\"\"\"\n",
    "\n",
    "# Save the Streamlit app code into a Python file using UTF-8 encoding\n",
    "with open('resume_classification_app.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(streamlit_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eacef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
